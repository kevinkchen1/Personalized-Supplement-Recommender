{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb97c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://www.mayoclinic.org/drugs-supplements-{}\"\n",
    "\n",
    "\"\"\"def fetch_page(slug):\n",
    "    url = BASE_URL.format(slug)\n",
    "    html = requests.get(url).text\n",
    "    return BeautifulSoup(html, \"html.parser\")\"\"\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "def fetch_page(slug):\n",
    "    url = BASE_URL.format(slug)\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a5e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplements_links = [\n",
    "    \"acidophilus/art-20361967\",\"aloe/art-20362267\",\"coenzyme-q10/art-20362602\",\"creatine/art-20347591\",\"dhea/art-20364199\",\n",
    "    \"primrose/art-20364500\",\"fish-oil/art-20364810\",\"flaxseed-and-flaxseed-oil/art-20366457\",\n",
    "    \"folate/art-20364625\",\"ginkgo/art-20362032\",\"glucosamine/art-20362874\",\"honey/art-20363819\",\"l-arginine/art-20364681\",\n",
    "    \"marijuana/art-20364974\",\"melatonin/art-20363071\",\"milk-thistle/art-20362885\",\"niacin/art-20364984\",\"red-yeast-rice/art-20363074\",\n",
    "    \"same/art-20364924\",\"st-johns-wort/art-20362212\",\"tea-tree-oil/art-20364246\",\"vitamin-a/art-20365945\",\"vitamin-b6/art-20363468\",\n",
    "    \"vitamin-b12/art-20363663\",\"vitamin-c/art-20363932\",\"vitamin-d/art-20363792\",\"vitamin-e/art-20364144\",\"zinc/art-20366112\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323b2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(soup):\n",
    "    sections = {}\n",
    "    current_heading = None\n",
    "\n",
    "    for el in soup.find_all([\"h2\",\"h3\",\"h4\",\"p\",\"li\"]):\n",
    "        text = el.get_text(strip=True)\n",
    "        if el.name in [\"h2\",\"h3\",\"h4\"]:\n",
    "            current_heading = text\n",
    "            sections[current_heading] = []\n",
    "        elif current_heading:\n",
    "            sections[current_heading].append(text)\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68568a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_data(slug, sections):\n",
    "    \"\"\"\n",
    "    Normalize Mayo Clinic supplement data into a flat, CSV-safe structure.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # NAME\n",
    "    # -------------------------\n",
    "    name = slug.split(\"/\")[0].title()\n",
    "    # -------------------------\n",
    "    # CATEGORY\n",
    "    # -------------------------\n",
    "    overview_text = \" \".join(sections.get(\"Overview\", [])).lower()\n",
    "\n",
    "    if \"vitamin\" in overview_text:\n",
    "        category = \"Vitamin\"\n",
    "    elif \"mineral\" in overview_text:\n",
    "        category = \"Mineral\"\n",
    "    elif any(w in overview_text for w in [\"plant\", \"herb\", \"extract\", \"gel\", \"latex\"]):\n",
    "        category = \"Herb / Plant-based\"\n",
    "    else:\n",
    "        category = \"Supplement\"\n",
    "\n",
    "    # -------------------------\n",
    "    # SAFETY INFO\n",
    "    # -------------------------\n",
    "    safety_lines = sections.get(\"Safety and side effects\", [])\n",
    "    safety_info = \" \".join(safety_lines) if safety_lines else \"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # CONTRAINDICATIONS\n",
    "    # -------------------------\n",
    "    contraindications = []\n",
    "\n",
    "    contraindication_keywords = [\n",
    "        \"should not\",\n",
    "        \"do not take\",\n",
    "        \"do not use\",\n",
    "        \"avoid\",\n",
    "        \"unsafe\",\n",
    "        \"pregnant\",\n",
    "        \"breastfeeding\",\n",
    "        \"children\",\n",
    "        \"surgery\",\n",
    "        \"kidney\",\n",
    "        \"liver\"\n",
    "    ]\n",
    "\n",
    "    for line in safety_lines:\n",
    "        if any(k in line.lower() for k in contraindication_keywords):\n",
    "            contraindications.append(line.strip())\n",
    "\n",
    "    contraindications_str = \" | \".join(contraindications)\n",
    "\n",
    "    # -------------------------\n",
    "    # DRUG INTERACTIONS\n",
    "    # -------------------------\n",
    "    interaction_lines = sections.get(\"Interactions\", [])\n",
    "    interaction_entries = []\n",
    "    \n",
    "    # Unwanted string to filter out\n",
    "    unwanted_text = \"There is a problem with information submitted for this request\"\n",
    "\n",
    "    for line in interaction_lines:\n",
    "        # Skip lines containing the unwanted text\n",
    "        if unwanted_text in line:\n",
    "            continue\n",
    "            \n",
    "        # Extract drug name (best-effort)\n",
    "        match = re.match(r\"^([A-Za-z0-9 ,\\-]+)\\s*\\(\", line)\n",
    "        drug = match.group(1).strip() if match else line.split(\".\")[0]\n",
    "\n",
    "        # Severity heuristic\n",
    "        lower = line.lower()\n",
    "        if any(w in lower for w in [\"fatal\", \"kidney failure\", \"cancer\"]):\n",
    "            severity = \"Severe\"\n",
    "        elif any(w in lower for w in [\"bleeding\", \"hypoglycemia\", \"electrolyte\"]):\n",
    "            severity = \"Moderate\"\n",
    "        else:\n",
    "            severity = \"Mild\"\n",
    "\n",
    "        interaction_entries.append(\n",
    "            f\"{drug} ({severity}): {line.strip()}\"\n",
    "        )\n",
    "\n",
    "    drug_interactions_str = \" | \".join(interaction_entries)\n",
    "    \n",
    "    # Also remove the unwanted string from the final result if it somehow got through\n",
    "    # Handle both escaped newlines and actual newlines\n",
    "    unwanted_patterns = [\n",
    "        \" | There is a problem with\\\\n                                information submitted for this request (Mild): There is a problem with\\\\n                                information submitted for this request. Review/update the\\\\n                                information highlighted below and resubmit the form.\",\n",
    "        \" | There is a problem with\\n                                information submitted for this request (Mild): There is a problem with\\n                                information submitted for this request. Review/update the\\n                                information highlighted below and resubmit the form.\",\n",
    "        \"There is a problem with information submitted for this request\"\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        drug_interactions_str = drug_interactions_str.replace(pattern, \"\").strip()\n",
    "    \n",
    "    # Clean up any double separators that might result\n",
    "    drug_interactions_str = re.sub(r'\\s*\\|\\s*\\|\\s*', ' | ', drug_interactions_str).strip()\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"category\": category,\n",
    "        \"safety_info\": safety_info,\n",
    "        \"drug_interactions\": drug_interactions_str,\n",
    "        \"contraindications\": contraindications_str\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74940f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for sup in supplements_links:\n",
    "    soup = fetch_page(sup)\n",
    "    sections = extract_sections(soup)\n",
    "    data = normalize_data(sup, sections)\n",
    "    all_data.append(data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "627216ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSV from DataFrame\n",
    "df.to_csv(\"supplements_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplements Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"raw_mayo_data.csv\")\n",
    "\n",
    "df[\"sup_id\"] = [\"SUP\" + str(i).zfill(2) for i in range(1, len(df) + 1)]\n",
    "\n",
    "cols = [\"sup_id\"] + [c for c in df.columns if c != \"sup_id\"]\n",
    "df = df[[\"sup_id\", \"name\"]]\n",
    "\n",
    "df.to_csv(\"supplements_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54bca0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_symptom_phrases(text: str):\n",
    "    \"\"\"Heuristically extract short symptom-like phrases from safety text.\n",
    "\n",
    "    Pure-Python, no external NLP models.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    text = str(text).replace(\"\\n\", \" \")\n",
    "\n",
    "    # Rough sentence split\n",
    "    sentences = re.split(r\"[.!?]\", text)\n",
    "\n",
    "    trigger_words = (\n",
    "        \"cause\", \"causes\", \"causing\",\n",
    "        \"side effects\", \"side effect\",\n",
    "        \"can lead to\", \"may lead to\", \"might cause\",\n",
    "        \"can result in\", \"may result in\",\n",
    "    )\n",
    "\n",
    "    phrases = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        s = sent.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "\n",
    "        lower = s.lower()\n",
    "        if not any(tw in lower for tw in trigger_words):\n",
    "            continue\n",
    "\n",
    "        # Look for common patterns like \"can cause X\", \"may cause X\", \"side effects include X\"\n",
    "        pattern_parts = [\n",
    "            r\"side effects? (include|may include|might include) (?P<rest>.+)\",\n",
    "            r\"(can|may|might) cause (?P<rest>.+)\",\n",
    "            r\"cause (?P<rest>.+)\",\n",
    "            r\"can lead to (?P<rest>.+)\",\n",
    "            r\"may lead to (?P<rest>.+)\",\n",
    "            r\"can result in (?P<rest>.+)\",\n",
    "            r\"may result in (?P<rest>.+)\",\n",
    "        ]\n",
    "\n",
    "        extracted = None\n",
    "        for pat in pattern_parts:\n",
    "            m = re.search(pat, lower)\n",
    "            if m:\n",
    "                # Map back to original casing using span of match\n",
    "                span = m.span(\"rest\")\n",
    "                extracted = s[span[0]:span[1]]\n",
    "                break\n",
    "\n",
    "        if not extracted:\n",
    "            # Fallback: use entire sentence body after first comma\n",
    "            parts = s.split(\",\", 1)\n",
    "            extracted = parts[-1]\n",
    "\n",
    "        # Now split the extracted span into candidate phrases\n",
    "        for chunk in re.split(r\",| and | or \", extracted):\n",
    "            phrase = chunk.strip().strip(\"'\\\"()[] \")\n",
    "            phrase = re.sub(r\"^(such as|including|like) \", \"\", phrase, flags=re.IGNORECASE)\n",
    "            if not phrase:\n",
    "                continue\n",
    "\n",
    "            # Filter: no digits, reasonable length\n",
    "            if any(ch.isdigit() for ch in phrase):\n",
    "                continue\n",
    "            words = phrase.split()\n",
    "            if not (1 <= len(words) <= 4):\n",
    "                continue\n",
    "\n",
    "            phrases.append(phrase.lower())\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    clean = []\n",
    "    for p in phrases:\n",
    "        if p not in seen:\n",
    "            seen.add(p)\n",
    "            clean.append(p)\n",
    "\n",
    "    return clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web-scrape Mayo Clinic again to build symptom vocabulary and mappings\n",
    "\n",
    "all_symptom_phrases = set()\n",
    "supp_symptom_rows = []\n",
    "\n",
    "for idx, slug in enumerate(supplements_links):\n",
    "    sup_id = f\"SUP{idx+1:02d}\"\n",
    "\n",
    "    soup = fetch_page(slug)\n",
    "    sections = extract_sections(soup)\n",
    "\n",
    "    # Use only the safety section text\n",
    "    safety_text = \" \".join(sections.get(\"Safety and side effects\", []))\n",
    "    phrases = extract_symptom_phrases(safety_text)\n",
    "\n",
    "    for p in set(phrases):  # unique per supplement\n",
    "        all_symptom_phrases.add(p)\n",
    "        supp_symptom_rows.append({\"sup_id\": sup_id, \"symptom\": p})\n",
    "\n",
    "# Build global symptom vocabulary with IDs\n",
    "all_symptom_phrases = sorted(all_symptom_phrases)\n",
    "\n",
    "symptoms_df = pd.DataFrame({\n",
    "    \"symptom_id\": [f\"SMP{str(i).zfill(3)}\" for i in range(1, len(all_symptom_phrases) + 1)],\n",
    "    \"symptom\": all_symptom_phrases,\n",
    "})\n",
    "\n",
    "symptoms_df.to_csv(\"symptoms_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19999a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
